{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYhPFKLvCFFBOQGfNN79YT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imeldp96/qsar_study/blob/main/XGBoost_Regressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Siu6GV-1rBNS"
      },
      "outputs": [],
      "source": [
        "!pip install kennard_stone #to install kennard-stone splitting algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "ZHDt_37ZrTB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to import dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame as df\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score, r2_score, mean_absolute_percentage_error\n",
        "#import kennard_stone as ks #import kennard_stone as ks #activate this line to install ks as well (after installing), deactivate if not needed\n",
        "\n",
        "random = 42 #random number for consistent results, can be changed to anything"
      ],
      "metadata": {
        "id": "ZylEcKQErXFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data/all.csv', index_col=[0], header=[0]) #change accordingly with the location of your csv file"
      ],
      "metadata": {
        "id": "PfizZg0wrjT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X= data.drop('pIC50', axis=1) #Select the descriptor's columns\n",
        "\n",
        "#X=data[['X3', 'X21','X11']] #vi-qc\n",
        "#X=data[['X11', 'X15', 'X16']] #ga-qc\n",
        "\n",
        "y = data['pIC50']  # Setting y as the target variable.\n",
        "X.head()"
      ],
      "metadata": {
        "id": "b0ZL3jHUrj85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kennard-Stone Algorithm for training-test set division\n",
        "#X_train, X_test, y_train, y_test = ks.train_test_split(X, y, test_size=0.2) #change test_size accordingly with the proportion of training-test set"
      ],
      "metadata": {
        "id": "noQgjyJMrpPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dont run this if you run the KS set division\n",
        "#only run this if the training and test set has been divided into different rows\n",
        "\n",
        "X_train = X.iloc[:19] #select rows for train set\n",
        "X_test = X.iloc[19:28] #select rows for test set\n",
        "\n",
        "y_train = y.iloc[:19]\n",
        "y_test = y.iloc[19:28]"
      ],
      "metadata": {
        "id": "7jlKhiUqrsmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "id": "7molUwOWruOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HYPERPARAMETERS TUNING"
      ],
      "metadata": {
        "id": "rGpcxt4urvC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from pprint import pprint\n",
        "import joblib\n",
        "from functools import partial\n",
        "\n",
        "# Suppressing warnings because of skopt verbosity\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Classifier/Regressor\n",
        "import xgboost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer"
      ],
      "metadata": {
        "id": "f1SL-Tbtrxk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search\n",
        "\n",
        "param_grid = {'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
        "    'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'max_depth': [6, 8, 10, 12],\n",
        "    'min_child_weight':[0, 1, 10],\n",
        "    'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
        "    'gamma' : [0, 0.1, 0.5, 1.0],\n",
        "    'reg_alpha' : [0, 1, 10, 20],\n",
        "    'reg_lambda' : [0, 1, 10, 20]\n",
        "              } #you can modify the range\n",
        "# Create a based model\n",
        "xgb = XGBRegressor(booster='gbtree', device='cpu', objective='reg:squarederror', verbosity=2, tree_method='auto', n_jobs=-1)\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = xgb, param_grid = param_grid,\n",
        "                          cv = 8, n_jobs = -1, verbose = 2, scoring=['r2', 'neg_mean_squared_error'], refit = 'neg_mean_squared_error')"
      ],
      "metadata": {
        "id": "0aiiozGAr7we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "K6T6pQ-qsZAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_xgb = XGBRegressor(**best_params, random_state=random, booster='gbtree', objective='reg:squarederror', verbosity=2, tree_method='auto') #fitting the best hyperparams\n",
        "optimized_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OG-x18hTsfbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBRegressor"
      ],
      "metadata": {
        "id": "BxD4JcYMsj1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "1Q4iNIAhsqPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_fit = optimized_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5oHiXePcstfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on the training dataset\n",
        "ytrain_pred = xgb_fit.predict(X_train)\n",
        "#training model evaluation\n",
        "#training r-sq\n",
        "print('The training r_sq is: %.3f'% xgb_fit.score(X_train, y_train))\n",
        "#RMSE\n",
        "print('The RMSE is: %.3f'% np.sqrt(mean_squared_error(y_train, ytrain_pred)))\n",
        "#MAPE\n",
        "print('The MAPE is: %.3f'% mean_absolute_percentage_error(y_train, ytrain_pred))"
      ],
      "metadata": {
        "id": "A4mSe3DUszRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on the testing data\n",
        "ytest_pred = xgb_fit.predict(X_test)\n",
        "\n",
        "#testing coef. of determination\n",
        "print('The testing r_sq is: %.3f'% r2_score(y_test, ytest_pred))\n",
        "#model evaluation metrics on test set\n",
        "#RMSE\n",
        "print('The RMSE is: %.3f'% np.sqrt(mean_squared_error(y_test, ytest_pred)))\n",
        "#MAPE\n",
        "print('The MAPE is: %.3f'% mean_absolute_percentage_error(y_test, ytest_pred))"
      ],
      "metadata": {
        "id": "pvGj460Ss2im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the predicted targets\n",
        "df_ytrain = pd.DataFrame(y_train)\n",
        "df_ytrainpred = pd.DataFrame(ytrain_pred)\n",
        "df_ytest = pd.DataFrame(y_test)\n",
        "df_ytestpred = pd.DataFrame(ytest_pred)\n",
        "\n",
        "print(df_ytrainpred)\n",
        "print(df_ytestpred)\n"
      ],
      "metadata": {
        "id": "mBcGpeaqs9Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_scatter_with_line(y_train, y_train_pred, y_test, y_test_pred):\n",
        "    fig = plt.figure(figsize=(8, 8))  # Set the figure size\n",
        "    plt.scatter(y_train, y_train_pred, color='blue', label='Training Set', alpha=0.5, s=70)\n",
        "    plt.scatter(y_test, y_test_pred, color='red', label='Test Set', alpha=0.5, s=50)\n",
        "    plt.plot([np.min(np.concatenate([y_train, y_test])), np.max(np.concatenate([y_train, y_test]))],\n",
        "             [np.min(np.concatenate([y_train, y_test])), np.max(np.concatenate([y_train, y_test]))],\n",
        "             color='black', linestyle='--')  # Diagonal line\n",
        "    plt.title('Experimental vs Predicted', fontsize=16)\n",
        "    plt.xlabel('Experimental', fontsize=14)\n",
        "    plt.ylabel('Predicted', fontsize=14)\n",
        "    plt.axis('square')  # Set aspect ratio to be equal\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Set face color of the figure to white\n",
        "    fig.patch.set_facecolor('none')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have y_train, ytrain_pred, y_test, and ytest_pred as arrays\n",
        "plot_scatter_with_line(y_train, ytrain_pred, y_test, ytest_pred)"
      ],
      "metadata": {
        "id": "l1hrWroetC3P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}